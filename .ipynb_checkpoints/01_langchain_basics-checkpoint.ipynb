{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288ce9a8",
   "metadata": {
    "id": "288ce9a8"
   },
   "source": [
    "# LangChain Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2905610-9ad8-43fd-bb28-31a404ea28fe",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d92f1",
   "metadata": {
    "executionInfo": {
     "elapsed": 6656,
     "status": "ok",
     "timestamp": 1695281250556,
     "user": {
      "displayName": "Andrei Dumitrescu",
      "userId": "04285534149796751164"
     },
     "user_tz": -180
    },
    "id": "002d92f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534918b-a514-4df1-b7eb-21e5f9f94d11",
   "metadata": {},
   "source": [
    "### Verify if LangChain is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2f431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4913,
     "status": "ok",
     "timestamp": 1695281268475,
     "user": {
      "displayName": "Andrei Dumitrescu",
      "userId": "04285534149796751164"
     },
     "user_tz": -180
    },
    "id": "bdf2f431",
    "outputId": "01809e7f-0539-4eae-b6af-19117ab595eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4407a3a",
   "metadata": {
    "id": "f4407a3a"
   },
   "source": [
    "#### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9420415",
   "metadata": {
    "id": "d9420415",
    "outputId": "0e64cc2d-6d74-41b7-a8c2-b311e2b72ebc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys (Cohere, Pinecone) from .env \n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "COHERE_API_KEY = os.environ.get('COHERE_API_KEY')\n",
    "print(COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e63e31-28ad-4d89-866f-238f818c4315",
   "metadata": {},
   "source": [
    "## Early Experimentation with LLMs Using LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975fc78c-0143-4c44-91a9-d89c609f484d",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. It enables applications that:\n",
    "\n",
    "- Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)\n",
    "\n",
    "- Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29231e2",
   "metadata": {
    "id": "e29231e2"
   },
   "source": [
    "### LLM Models (Wrappers): Cohere\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/cohere\n",
    "\n",
    "Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.\n",
    "\n",
    "- Founded in 2020\n",
    "- Based in Toronto, Canada "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d5b42-233d-45af-95c5-e2c0413b4015",
   "metadata": {},
   "source": [
    "#### Setting up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37cc56",
   "metadata": {
    "id": "8d37cc56",
    "outputId": "0ce7f40e-3a0b-48f7-9bad-fd5b4fc91abe"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere\n",
    "\n",
    "# Create Cohere LLM instance with parameters\n",
    "llm = Cohere(\n",
    "            # A non-negative float that tunes the degree of randomness in generation.\n",
    "            # Higher values give more diverse, creative responses\n",
    "            # Lower values give more focused, deterministic responses\n",
    "            temperature=0.7, \n",
    "            # The maximum number of tokens to generate in the response\n",
    "            max_tokens=512, \n",
    "            cohere_api_key=COHERE_API_KEY)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538e0f1-f723-439d-82ce-fb9908cda59e",
   "metadata": {},
   "source": [
    "#### First try - test Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d355809",
   "metadata": {
    "id": "5d355809",
    "outputId": "d4362c8b-be35-43e2-81f9-8dfd9f4711b6"
   },
   "outputs": [],
   "source": [
    "# Generate response from LLM by invoking it \n",
    "output = llm.invoke('explain 5G networks in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c5e84",
   "metadata": {
    "id": "e29c5e84",
    "outputId": "4029edf6-7c35-4a06-dda7-e6093f356929"
   },
   "outputs": [],
   "source": [
    "# Pass prompt to LLM's get_num_tokens method\n",
    "num_tokens = llm.get_num_tokens('explain 5G networks in one sentence')\n",
    "\n",
    "# Print number of tokens in the tokenized prompt.\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fd88a",
   "metadata": {
    "id": "b98fd88a",
    "outputId": "9b1d4381-af93-4bf7-98cb-2a992155af78"
   },
   "outputs": [],
   "source": [
    "# Prompt LLM with two questions \n",
    "prompts = ['What is the date of the European Union creation.', \n",
    "           'What is the formula for the area of a room?']\n",
    "\n",
    "# Generate responses to prompts\n",
    "# In this example, we can't use invoke() -> we don't have a single prompt\n",
    "output = llm.generate(prompts)  \n",
    "\n",
    "# Print list of generated responses\n",
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8339a9-55f8-4c33-807d-cd66bf38882a",
   "metadata": {},
   "source": [
    "#### Example in order to extract the answer of the  first question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0725e38",
   "metadata": {
    "id": "e0725e38",
    "outputId": "cb53ba44-16ef-4011-a757-bd5770cce2cc"
   },
   "outputs": [],
   "source": [
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42ee2d-f74b-40aa-8e42-07d417090f92",
   "metadata": {
    "id": "7703b86d",
    "outputId": "74a7c223-0098-460c-c333-37a5925b42f6"
   },
   "source": [
    "#### understand the difference between invoke() and generate() - check here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39444a1c-7fd3-4d7b-bbe4-2f8bbdca259e",
   "metadata": {},
   "source": [
    "https://chat.langchain.com/  \n",
    "https://python.langchain.com/docs/get_started/introduction\n",
    "https://api.python.langchain.com/en/latest/langchain_api_reference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ee709",
   "metadata": {
    "id": "c20ee709"
   },
   "source": [
    "## Deep dive into LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ad29b",
   "metadata": {
    "id": "6d3ad29b"
   },
   "source": [
    "### Prompt Templates\n",
    "\n",
    "https://python.langchain.com/docs/modules/model_io/prompts/quick_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ed8a8",
   "metadata": {
    "id": "612ed8a8",
    "outputId": "7cf93377-faea-47c8-a86e-d23de5591459"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define template with input variables in braces\n",
    "template = '''You are an experienced mathematician professor.\n",
    "Write a few sentences about the following mathematical {concept} in {language}.'''\n",
    "\n",
    "# Create PromptTemplate object with input variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['concept', 'language'], # list of input variable names\n",
    "    template=template # template string\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28accc9",
   "metadata": {
    "id": "b28accc9",
    "outputId": "9a33f6f3-5b1c-4688-b5c9-51f1419ce176"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere\n",
    "\n",
    "# Create Cohere LLM instance with parameters\n",
    "llm = Cohere(temperature=0.7, max_tokens=512, cohere_api_key=COHERE_API_KEY)\n",
    "print(llm)\n",
    "\n",
    "# Format prompt template with input values \n",
    "output = llm(prompt.format(concept='Pythagorean theorem', language='Spanish'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b22ac-3f0b-4128-8e55-ab5f99359bb9",
   "metadata": {},
   "source": [
    "### Learn about Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd00f0-afb9-4a64-8788-5d9f0f68306d",
   "metadata": {},
   "source": [
    "Resources :\n",
    "\n",
    "https://python.langchain.com/docs/modules/chains  \n",
    "https://chat.langchain.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d9b84",
   "metadata": {
    "id": "025d9b84"
   },
   "source": [
    "#### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e5278",
   "metadata": {
    "id": "fd1e5278"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatCohere\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Create ChatCohere LLM instance\n",
    "llm = ChatCohere(temperature=0.5, cohere_api_key=COHERE_API_KEY)\n",
    "\n",
    "# Define template string \n",
    "template = '''You are an experienced mathematician professor.\n",
    "Write a few sentences about the following mathematical {concept} in {language}.'''\n",
    "\n",
    "# Create PromptTemplate \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['concept', 'language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Create LLMChain with llm and prompt\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run chain with input values\n",
    "output = chain.invoke({'concept': 'Pythagorean theorem', 'language': 'Spanish'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283cc13",
   "metadata": {
    "id": "f283cc13"
   },
   "source": [
    "#### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68115d",
   "metadata": {
    "id": "9d68115d",
    "outputId": "2aa75fcc-88bb-4972-c9dc-0eec0f0b7d07",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatCohere\n",
    "from langchain.llms import Cohere\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Create Cohere LLM instance with parameters\n",
    "llm1 = Cohere(temperature=0.2, max_tokens=512, cohere_api_key=COHERE_API_KEY)\n",
    "\n",
    "# Create first prompt template\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "\n",
    "# Create first LLMChain with llm1 and prompt1\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "# Create ChatCohere LLM instance\n",
    "llm2 = ChatCohere(temperature=0.9, cohere_api_key=COHERE_API_KEY)\n",
    "\n",
    "# Create second prompt template\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "\n",
    "# Create second LLMChain with llm2 and prompt2\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "# Create SequentialChain using the two chains \n",
    "# You can check what verbose means with :\n",
    "# https://api.python.langchain.com/en/latest/chains/langchain.chains.sequential.SimpleSequentialChain.html?highlight=simplesequentialchain%20verbose\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "# Run the chain with the input 'softmax'\n",
    "output = overall_chain.run('softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9c39",
   "metadata": {
    "id": "ed3a9c39"
   },
   "source": [
    "#### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e2fe3",
   "metadata": {
    "id": "115e2fe3",
    "outputId": "e7b894b6-3eee-41b4-faf3-171d2aed2f42"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.llms import Cohere\n",
    "\n",
    "# Create Cohere LLM instance\n",
    "llm = Cohere(temperature=0, cohere_api_key=COHERE_API_KEY)\n",
    "\n",
    "# Create agent by passing LLM, tool (what is it !?)\n",
    "# You can check what verbose means with :\n",
    "# https://api.python.langchain.com/en/latest/chains/langchain.chains.sequential.SimpleSequentialChain.html?highlight=simplesequentialchain%20verbose\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run agent with input command \n",
    "agent_executor.run('what is the answer to x**3 + 3*x**2 - 5 with x = 2157625176 ?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd05163-2f89-45f6-9d2d-28d3b4f18df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
